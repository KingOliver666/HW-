---
title: "STATS 506 HW3"
format: html
editor: visual
---

## Problem 2

```{r}
library(DBI)
library(RSQLite)

sakila <- dbConnect(RSQLite :: SQLite(), "C:/Users/Lenovo/Downloads/sakila_master.db")

dbListTables(sakila)

```

```{r}
dbListFields(sakila, "film")
```

```{r}
dbGetQuery(sakila, "SELECT * FROM language LIMIT 10")
```

Part(a):

```{r}
dbGetQuery(sakila, "SELECT l.name, language_id, COUNT(language_id)
                    FROM film f
                    JOIN language l USING(language_id)
                    WHERE language_id != 1
                    GROUP BY l.name, language_id
                    ORDER BY COUNT(language_id)")

                   
```

Answer: This tells us that all movies use language of English, there is no movie use other one of five language.

Part(b):

we first use SQL query to solve this problem

```{r}
dbGetQuery(sakila, "SELECT category_id, c.name, COUNT(category_id)
                    FROM film f
                    JOIN film_category fc USING (film_id)
                    JOIN category c USING (category_id)
                    GROUP BY category_id, c.name
                    ORDER BY COUNT(category_id) DESC
                    LIMIT 5")
```

Then we will use R to solve this problem

```{r}
##extract three tables from our database
table_film <- dbGetQuery(sakila, " SELECT *
                                   FROM film")

table_fcate <-dbGetQuery(sakila, "SELECT *
                                  FROM film_category")

table_cate <- dbGetQuery(sakila, "SELECT *
                                  FROM category")
```

```{r}
library(dplyr)
## we first join first two tables
join1 <- inner_join(table_film, table_fcate, by = "film_id")

## we then join the table "join1" with our last table
join_final <- inner_join(join1, table_cate, by = "category_id")
```

```{r}
frequency_table <- table(join_final$category_id)
number_movie <- max(frequency_table)
max_category_id <- as.integer(names(frequency_table[which.max(frequency_table)]))
vector <- join_final$name[which(join_final$category_id == max_category_id)]
print(c(vector[1], number_movie))
```

Answer: thus, we have found that the genre of the movie that most common in the data is "sport", and there are totally 74 movies of this genre.

Part(c)

We first solve this problem use SQL

```{r}
dbGetQuery(sakila, " SELECT country, co.country_id
                      FROM customer c
                      JOIN address a USING(address_id)
                      JOIN city ci USING(city_id)
                      JOIN country co ON co.country_id = ci.country_id
                      GROUP BY country, co.country_id
                      HAVING COUNT(customer_id) = 9")
```

Now we solve this problem use R

```{r}
table_connected <-dbGetQuery(sakila, "SELECT *
                                    FROM customer c
                                    JOIN address a USING(address_id)
                                    JOIN city ci USING(city_id)
                                    JOIN country co 
                                      ON co.country_id = ci.country_id
                                    ")


country_freq <- table(table_connected$country)

country_9 <- names(country_freq[which(country_freq == 9)])
country_9
```

Answer: So by use both method, we find the country have exactly 9 customers is United Kingdom.

## Problem 3

```{r}
setwd("C:/Users/Lenovo/Downloads")
data <- read.csv("us-500.csv", header = TRUE)
```

Part(a)ï¼š

```{r}
num_row <- nrow(data)
proportion_net <- sum(grepl("net", data$email)) / num_row
proportion_net
```

Answer : There are about 14.6% of email address are hosted at a domain with TLD ".net".

Part(b):

```{r}
alpnum <-grepl("^[[:alnum:]]+@", data$email)
nonalpnum_prop <- 1 - sum(alpnum) / num_row
nonalpnum_prop
```

Answer: So there are about 50.6% emails that have at least one non alphanumeric character.

Part(c): we first check if for each person, his or her area code "phone1" and "phone2" matches.

```{r}
all.equal(substr(data$phone1, 1, 3), substr(data$phone2, 1, 3))
```

Because the result of the above code is "true", then it suffices to determine the most common area code for "phone1".

```{r}
area_code <- substr(data$phone1, 1, 3)
area_code_table <- table(area_code)
MostCommon_code <- names(area_code_table[which.max(area_code_table)])
MostCommon_code
```

Answer: so the most common area code among all phone numbers is "973"

Part(d):

we first extract all apartment number using for loop

```{r}
address <- strsplit(data$address, " ")

apart <- rep(NA, num_row)

for (i in 1: num_row){
  apart[i] <- address[[i]][length(address[[i]])]
}

apart_num<- apart[grep("#", apart)]

# remove "#" and store those integers in a vector
length <- length(apart_num)
for (i in 1: length){
  apart_num[i] <- substr(apart_num[i], 2, nchar(apart_num[i]))
}

apart_num <- as.numeric(apart_num)
```

Thus we now have constructed the vector of apartment number, then we will start to draw a histgram:

```{r}
hist(log(apart_num), xlab = "log of apartment number")

```

Part(e):

We first find the leading number for each element in the vector "apart_num"

```{r}
apart_char <- as.character(apart_num)
lead_dig <- as.numeric(substr(apart_char, 1, 1))
```

Then we will construct a vector to store the expected value for each number in sample size of 500. And I just copy the probability of leading digit for each number (1-9) from material that professor provided as store it as a vector named expected_prob

```{r}
expected_prob <- c(0.301, 0.176, 0.125, 0.097, 0.079, 0.067, 0.058, 0.051, 0.046)

observed_value <- as.vector(table(lead_dig))
```

Now, we will do a Chi-squared test to check if the leading digit we observed follows Benford' s law.

```{r}
chisq.test(observed_value, p = expected_prob)

```

Answer : by using Chi-squared test, the p-value is less than 2.214e-10, meaning we will move to alternative hypothesis that the distribution of leading digit what we observed does not follow Benford's law. So maybe the apartment numbers would not pass as real data.

Part(f):

we first find street number for each person

```{r}
street <- rep(NA, num_row)

for (i in 1: num_row){
  street[i] <- address[[i]][1]
}

# Then I will get the vector of last digit using for loop
last_digit <- rep(NA, num_row)

for (i in 1: num_row){
  last_digit[i] <- as.numeric(substr(street[i], nchar(street[i]), nchar(street[i])))
}

```

Version1: Since I'm not sure if there exist a last digit law, I read some materials from professor provided and I assume the probability of last digit for each number is 0.1. So I will first solve the problem under my assumption.

```{r}
count_last <- as.vector(table(last_digit))
chisq.test(count_last, p = rep(0.1, 10))
```

The P-value is 0.2156, so if my assumption holds, then we fail to reject H_0, and we may conclude that the last_digit we observed follows Benford's law of last digit.

Version2: Now I will assume that the last digit follows Benford's law of leading digit, then I need to remove all 0's, and then do a Chi-Squared test

```{r}
newlast_digit <- last_digit[last_digit != 0]
chisq.test(as.vector(table(newlast_digit)), p = expected_prob)
```

Then under our assumption, we may say it seems that the last digit we observed does not follow Benford' s law since we got very small p-value.
